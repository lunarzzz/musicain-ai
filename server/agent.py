"""Agent ç¼–æ’æ ¸å¿ƒ â€” æ„å›¾è¯†åˆ« â†’ å·¥å…·è°ƒç”¨ â†’ ç»“æœåˆæˆ â†’ å“åº”ç»„è£…

é‡‡ç”¨ LangChain çš„ create_tool_calling_agentï¼Œé…åˆ Function Calling
å®ç°å¤šæ­¥æ¨ç†ä¸å·¥å…·è°ƒåº¦ã€‚
"""

from __future__ import annotations

import json
import uuid
from typing import AsyncGenerator

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI

from config import settings
from models import CardData, CardType, Evidence, StreamChunk
import database as db
from skills.router import route as route_skill, get_skills_description

# â”€â”€ å¯¼å…¥æ‰€æœ‰ Tools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from tools.hot_trends import get_trending_topics, generate_song_inspiration, generate_promo_tags
from tools.promotion import recommend_songs_to_promote, generate_promotion_plan, get_promotion_report
from tools.analytics import get_audience_portrait, analyze_cross_platform, explain_metric_change
from tools.knowledge import search_knowledge, check_upload_compliance

ALL_TOOLS = [
    get_trending_topics,
    generate_song_inspiration,
    generate_promo_tags,
    recommend_songs_to_promote,
    generate_promotion_plan,
    get_promotion_report,
    get_audience_portrait,
    analyze_cross_platform,
    explain_metric_change,
    search_knowledge,
    check_upload_compliance,
]

TOOL_MAP = {t.name: t for t in ALL_TOOLS}

# â”€â”€ System Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SYSTEM_PROMPT = """ä½ æ˜¯ã€Œè…¾è®¯éŸ³ä¹äºº AI åŠ©æ‰‹ã€ï¼Œä¸€ä¸ªä¸“ä¸šçš„éŸ³ä¹äººå·¥ä½œæµ Copilotã€‚

## ä½ çš„èƒ½åŠ›
ä½ å¯ä»¥é€šè¿‡è°ƒç”¨å·¥å…·æ¥å¸®åŠ©éŸ³ä¹äººå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
1. **çƒ­ç‚¹åˆ›ä½œ**ï¼šè·å–çƒ­ç‚¹è¶‹åŠ¿ã€ç”Ÿæˆæ­Œåçµæ„Ÿã€ç”Ÿæˆå®£æ¨æ ‡ç­¾
2. **å®£æ¨å»ºè®®**ï¼šæ¨èæœ€å€¼å¾—å®£æ¨çš„æ­Œæ›²ã€ç”ŸæˆæŠ•æ”¾è®¡åˆ’ã€æŠ•åå¤ç›˜
3. **æ™ºèƒ½åˆ†æ**ï¼šå¬ä¼—ç”»åƒã€è·¨å¹³å°è¡¨ç°åˆ†æã€å…³é”®æŒ‡æ ‡å˜åŒ–å½’å› 
4. **é—®ç­”æŒ‡å—**ï¼šå›ç­”å…¥é©»ã€ä¸Šä¼ ã€å®¡æ ¸ã€ç»“ç®—ã€ç‰ˆæƒã€æ´»åŠ¨ç­‰é—®é¢˜

## è¡Œä¸ºå‡†åˆ™
- **å§‹ç»ˆæä¾›å¯æ‰§è¡Œçš„å»ºè®®**ï¼Œä¸è¦åªç»™ç¬¼ç»Ÿçš„æ–¹å‘
- **å¼•ç”¨æ•°æ®æ—¶æ ‡æ³¨æ¥æºå’Œå£å¾„**ï¼Œç¡®ä¿å¯ä¿¡åº¦
- **è¯­æ°”ä¸“ä¸šä½†äº²åˆ‡**ï¼Œåƒä¸€ä½èµ„æ·±çš„éŸ³ä¹è¡Œä¸šå‰è¾ˆ
- **ä¸»åŠ¨æ¨èä¸‹ä¸€æ­¥åŠ¨ä½œ**ï¼Œå¸®éŸ³ä¹äººåšåˆ°"é—­ç¯"
- **å½“ä¸ç¡®å®šæ—¶ï¼Œè¯šå®è¯´æ˜**å¹¶å¼•å¯¼ç”¨æˆ·è”ç³»äººå·¥å®¢æœ
- å›å¤ä½¿ç”¨ä¸­æ–‡ï¼Œæ ¼å¼æ¸…æ™°ç¾è§‚ï¼Œå–„ç”¨ Markdown æ’ç‰ˆ

## é‡è¦è§„åˆ™
- ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„æ•°æ®ï¼Œåªä½¿ç”¨å·¥å…·è¿”å›çš„çœŸå®æ•°æ®
- å¦‚æœç”¨æˆ·çš„é—®é¢˜è¶…å‡ºä½ çš„èƒ½åŠ›èŒƒå›´ï¼Œå‹å¥½åœ°è¯´æ˜å¹¶å»ºè®®æ›¿ä»£æ–¹æ¡ˆ
- åœ¨ç»™å‡ºå»ºè®®æ—¶ï¼Œå°½é‡é™„å¸¦ç†ç”±å’Œä¾æ®

""" + "\n\n" + get_skills_description()


# â”€â”€ Agent æ ¸å¿ƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _get_llm() -> ChatOpenAI:
    return ChatOpenAI(
        api_key=settings.LLM_API_KEY,
        base_url=settings.LLM_BASE_URL,
        model=settings.LLM_MODEL,
        temperature=settings.LLM_TEMPERATURE,
        streaming=True,
    )


def _build_messages(history: list[dict], user_msg: str) -> list:
    """æ„å»º LangChain æ¶ˆæ¯åˆ—è¡¨"""
    messages = [SystemMessage(content=SYSTEM_PROMPT)]

    for msg in history[-20:]:  # ä¿ç•™æœ€è¿‘ 20 æ¡å†å²
        role = msg.get("role", "user")
        content = msg.get("content", "")
        if role == "user":
            messages.append(HumanMessage(content=content))
        elif role == "assistant":
            messages.append(AIMessage(content=content))

    messages.append(HumanMessage(content=user_msg))
    return messages


def _generate_title(user_msg: str) -> str:
    """ä»é¦–æ¡æ¶ˆæ¯ç”Ÿæˆä¼šè¯æ ‡é¢˜"""
    title = user_msg.strip()[:30]
    if len(user_msg) > 30:
        title += "..."
    return title


def _extract_cards(tool_name: str, tool_result: dict) -> list[dict]:
    """ä»å·¥å…·è°ƒç”¨ç»“æœæå–å¯å±•ç¤ºçš„å¡ç‰‡æ•°æ®"""
    cards = []

    if tool_name == "get_trending_topics":
        topics = tool_result.get("topics", [])
        cards.append({
            "card_type": "hot_trend",
            "title": "ğŸ”¥ çƒ­ç‚¹è¶‹åŠ¿",
            "data": {"topics": topics, "updated_at": tool_result.get("updated_at")},
            "actions": [{"label": "åŸºäºçƒ­ç‚¹ç”Ÿæˆçµæ„Ÿ", "action_type": "callback", "payload": {"action": "generate_inspiration"}}],
        })

    elif tool_name == "generate_song_inspiration":
        cards.append({
            "card_type": "hot_trend",
            "title": "ğŸ’¡ åˆ›ä½œçµæ„Ÿ",
            "data": tool_result,
            "actions": [{"label": "ç”Ÿæˆå®£æ¨æ ‡ç­¾", "action_type": "callback", "payload": {"action": "generate_tags"}}],
        })

    elif tool_name in ("recommend_songs_to_promote",):
        recs = tool_result.get("recommendations", [])
        cards.append({
            "card_type": "song_recommend",
            "title": "ğŸµ æ¨æ­Œå»ºè®®",
            "data": {"recommendations": recs, "diagnosis": tool_result.get("diagnosis")},
            "actions": [{"label": "ç”ŸæˆæŠ•æ”¾è®¡åˆ’", "action_type": "callback", "payload": {"action": "create_plan"}}],
        })

    elif tool_name == "generate_promotion_plan":
        cards.append({
            "card_type": "promotion_plan",
            "title": "ğŸ“‹ æŠ•æ”¾è®¡åˆ’",
            "data": tool_result,
            "actions": [{"label": "å¼€å§‹æŠ•æ”¾", "action_type": "deeplink", "url": "/promotion/create"}],
        })

    elif tool_name == "get_promotion_report":
        cards.append({
            "card_type": "data_report",
            "title": "ğŸ“Š å®£æ¨å¤ç›˜æŠ¥å‘Š",
            "data": tool_result,
            "actions": [{"label": "è¿½åŠ æŠ•æ”¾", "action_type": "deeplink", "url": "/promotion/create"}],
        })

    elif tool_name == "get_audience_portrait":
        cards.append({
            "card_type": "audience_portrait",
            "title": "ğŸ‘¥ å¬ä¼—ç”»åƒ",
            "data": tool_result,
            "actions": [],
        })

    elif tool_name == "analyze_cross_platform":
        cards.append({
            "card_type": "data_report",
            "title": "ğŸ“ˆ è·¨å¹³å°åˆ†æ",
            "data": tool_result,
            "actions": [],
        })

    elif tool_name == "explain_metric_change":
        cards.append({
            "card_type": "data_report",
            "title": "ğŸ“‰ æŒ‡æ ‡å˜åŒ–åˆ†æ",
            "data": tool_result,
            "actions": [],
        })

    elif tool_name in ("search_knowledge", "check_upload_compliance"):
        cards.append({
            "card_type": "knowledge",
            "title": "ğŸ“– çŸ¥è¯†è§£ç­”",
            "data": tool_result,
            "actions": [{"label": "è”ç³»å®¢æœ", "action_type": "deeplink", "url": "/support"}],
        })

    return cards


async def chat(user_msg: str, conversation_id: str | None = None) -> AsyncGenerator[str, None]:
    """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œæµå¼è¿”å›å“åº”ã€‚

    äº§å‡º Server-Sent Events (SSE) æ ¼å¼çš„ JSON chunksã€‚
    """
    # 1. åˆ›å»ºæˆ–è·å–ä¼šè¯
    if not conversation_id or not db.get_conversation(conversation_id):
        conversation_id = db.create_conversation(_generate_title(user_msg))

    # 2. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
    db.save_message(conversation_id, "user", user_msg)

    # 3. åŠ è½½å†å²
    history = db.get_messages(conversation_id, limit=20)

    # 4. æ„å»ºæ¶ˆæ¯
    messages = _build_messages(history[:-1], user_msg)  # æ’é™¤åˆšå­˜çš„ç”¨æˆ·æ¶ˆæ¯

    # 5. Skill è·¯ç”±ï¼šåˆ¤æ–­æ˜¯å¦èµ°å¤šæ­¥ç¼–æ’
    matched_skill = route_skill(user_msg)

    all_cards = []
    full_content = ""
    message_id = uuid.uuid4().hex[:16]

    if matched_skill:
        # â”€â”€ Skill æ¨¡å¼ï¼šå¤šæ­¥å·¥ä½œæµ â”€â”€
        try:
            async for chunk in matched_skill.execute(user_msg, {}, TOOL_MAP):
                chunk_type = chunk.get("type")

                if chunk_type == "step_start":
                    step_chunk = json.dumps({
                        "type": "token",
                        "content": f"\n{chunk['description']}\n",
                    }, ensure_ascii=False)
                    full_content += f"\n{chunk['description']}\n"
                    yield f"data: {step_chunk}\n\n"

                elif chunk_type == "card":
                    all_cards.append(chunk["card"])
                    card_chunk = json.dumps({
                        "type": "card",
                        "card": chunk["card"],
                    }, ensure_ascii=False)
                    yield f"data: {card_chunk}\n\n"

                elif chunk_type == "token":
                    full_content += chunk.get("content", "")
                    token_chunk = json.dumps({
                        "type": "token",
                        "content": chunk["content"],
                    }, ensure_ascii=False)
                    yield f"data: {token_chunk}\n\n"

                elif chunk_type == "done":
                    pass  # ä¸‹é¢ç»Ÿä¸€å¤„ç†

        except Exception as e:
            error_msg = f"æŠ€èƒ½æ‰§è¡Œå‡ºé”™ï¼š{str(e)}"
            full_content = error_msg
            error_chunk = json.dumps({"type": "error", "content": error_msg}, ensure_ascii=False)
            yield f"data: {error_chunk}\n\n"

    else:
        # â”€â”€ Tool æ¨¡å¼ï¼šå•æ­¥ Function Calling â”€â”€
        llm = _get_llm()
        llm_with_tools = llm.bind_tools(ALL_TOOLS)

        try:
            # ç¬¬ä¸€è½®ï¼šLLM å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·
            response = await llm_with_tools.ainvoke(messages)

            # å¤„ç†å·¥å…·è°ƒç”¨
            if response.tool_calls:
                # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
                tool_messages = [response]
                for tool_call in response.tool_calls:
                    tool_name = tool_call["name"]
                    tool_args = tool_call["args"]
                    tool_fn = TOOL_MAP.get(tool_name)

                    if tool_fn:
                        try:
                            result = await tool_fn.ainvoke(tool_args)
                            if isinstance(result, str):
                                result = json.loads(result)
                        except Exception as e:
                            result = {"error": str(e)}

                        # æå–å¡ç‰‡
                        cards = _extract_cards(tool_name, result)
                        all_cards.extend(cards)

                        # å‘é€å¡ç‰‡ chunk
                        for card in cards:
                            card_chunk = json.dumps({
                                "type": "card",
                                "card": card,
                            }, ensure_ascii=False)
                            yield f"data: {card_chunk}\n\n"

                        # æ„å»ºå·¥å…·å“åº”æ¶ˆæ¯
                        from langchain_core.messages import ToolMessage
                        tool_messages.append(
                            ToolMessage(
                                content=json.dumps(result, ensure_ascii=False),
                                tool_call_id=tool_call["id"],
                            )
                        )

                # ç¬¬äºŒè½®ï¼šLLM åŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›ç­”
                messages.extend(tool_messages)
                async for chunk in llm.astream(messages):
                    if chunk.content:
                        full_content += chunk.content
                        token_chunk = json.dumps({
                            "type": "token",
                            "content": chunk.content,
                        }, ensure_ascii=False)
                        yield f"data: {token_chunk}\n\n"

            else:
                # æ— å·¥å…·è°ƒç”¨ï¼Œç›´æ¥æµå¼è¾“å‡º
                async for chunk in llm_with_tools.astream(messages):
                    if chunk.content:
                        full_content += chunk.content
                        token_chunk = json.dumps({
                            "type": "token",
                            "content": chunk.content,
                        }, ensure_ascii=False)
                        yield f"data: {token_chunk}\n\n"

        except Exception as e:
            error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ï¼š{str(e)}"
            full_content = error_msg
            error_chunk = json.dumps({
                "type": "error",
                "content": error_msg,
            }, ensure_ascii=False)
            yield f"data: {error_chunk}\n\n"

    # 7. ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯
    db.save_message(
        conversation_id,
        "assistant",
        full_content,
        cards=[c for c in all_cards] if all_cards else None,
    )

    # 8. æ›´æ–°ä¼šè¯æ ‡é¢˜ï¼ˆé¦–æ¬¡å¯¹è¯ï¼‰
    if len(history) <= 1:
        db.update_conversation_title(conversation_id, _generate_title(user_msg))

    # 9. å‘é€å®Œæˆ chunk
    done_chunk = json.dumps({
        "type": "done",
        "conversation_id": conversation_id,
        "message_id": message_id,
    }, ensure_ascii=False)
    yield f"data: {done_chunk}\n\n"
